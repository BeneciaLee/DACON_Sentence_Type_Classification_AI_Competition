{"cells":[{"cell_type":"markdown","source":["## 필요한 라이브러리 설치\n"],"metadata":{"id":"WduAKqJk60dH"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15606,"status":"ok","timestamp":1671750884091,"user":{"displayName":"jaewook Lee","userId":"02714897352724258647"},"user_tz":-540},"id":"2UvbsewY0fFf","outputId":"db98ff6b-ad00-4497-bd04-b66b4a36ecab"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytorch-lightning\n","  Downloading pytorch_lightning-1.8.6-py3-none-any.whl (800 kB)\n","\u001b[K     |████████████████████████████████| 800 kB 6.4 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (1.21.6)\n","Collecting tensorboardX>=2.2\n","  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n","\u001b[K     |████████████████████████████████| 125 kB 97.0 MB/s \n","\u001b[?25hRequirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (2022.11.0)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (6.0)\n","Collecting lightning-utilities!=0.4.0,>=0.3.0\n","  Downloading lightning_utilities-0.5.0-py3-none-any.whl (18 kB)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (4.64.1)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (4.4.0)\n","Collecting torchmetrics>=0.7.0\n","  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n","\u001b[K     |████████████████████████████████| 512 kB 83.2 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (21.3)\n","Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (1.13.0+cu116)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.23.0)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.3)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.8.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (22.1.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (2.1.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=17.0->pytorch-lightning) (3.0.9)\n","Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX>=2.2->pytorch-lightning) (3.19.6)\n","Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.8/dist-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2022.12.7)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (1.24.3)\n","Installing collected packages: torchmetrics, tensorboardX, lightning-utilities, pytorch-lightning\n","Successfully installed lightning-utilities-0.5.0 pytorch-lightning-1.8.6 tensorboardX-2.5.1 torchmetrics-0.11.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n","\u001b[K     |████████████████████████████████| 5.8 MB 8.0 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 42.6 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 81.7 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"]}],"source":["!pip install pytorch-lightning\n","!pip install transformers"]},{"cell_type":"markdown","source":["## 구글 드라이브 마운트"],"metadata":{"id":"uF4FqQbX8JST"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16048,"status":"ok","timestamp":1671750952922,"user":{"displayName":"jaewook Lee","userId":"02714897352724258647"},"user_tz":-540},"id":"Kh8Ch3rdzU16","outputId":"798211e9-0422-45c9-b958-7d70aae77fab"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["## 학습에서 사용되는 라이브러리 호출"],"metadata":{"id":"QS2BWKcL8Ob6"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"S4Ej2Sf_zLBj"},"outputs":[],"source":["import random\n","import pandas as pd\n","import numpy as np\n","import os\n","\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import train_test_split\n","from sklearn import preprocessing\n","from sklearn.metrics import f1_score\n","\n","import pytorch_lightning as pl\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","from torch.utils.data import Dataset, DataLoader\n","\n","from tqdm.auto import tqdm\n","from transformers import AutoModel, AutoTokenizer\n","\n","from torchmetrics.functional import accuracy,f1_score\n","\n","import warnings\n","warnings.filterwarnings(action='ignore') "]},{"cell_type":"markdown","source":["## 반복적인 검증을 위해서 시드 값 고정"],"metadata":{"id":"N9N3lor58Vg6"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"gRcEvnCP0pv3"},"outputs":[],"source":["def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True\n","\n","seed_everything(428)"]},{"cell_type":"markdown","source":["## 학습 데이터 및 테스트 데이터 호출"],"metadata":{"id":"qdlVGX638YHi"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"HiqSzepCzM67"},"outputs":[],"source":["train_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/DACON/문장_유형_분류_AI_경진대회/train.csv\")\n","test_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/DACON/문장_유형_분류_AI_경진대회/test.csv\")"]},{"cell_type":"markdown","source":["## 학습 데이터 데이터 프레임 확인\n","\n","학습 데이터에서는 테스트 데이터에 없는 `유형, 극성, 시제, 확실성, label` 데이터가 존재하는 것을 확인할 수 있습니다. 이를 이용한 학습을 수행하고자 합니다."],"metadata":{"id":"Aqp0-vIk8asq"}},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":315,"status":"ok","timestamp":1671751009267,"user":{"displayName":"jaewook Lee","userId":"02714897352724258647"},"user_tz":-540},"id":"9fzWIumYzfMa","colab":{"base_uri":"https://localhost:8080/","height":206},"outputId":"1e37efd9-b6f7-4c4e-8f5f-dc87702f1e14"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["            ID                                                 문장   유형  극성  \\\n","0  TRAIN_00000              0.75%포인트 금리 인상은 1994년 이후 28년 만에 처음이다.  사실형  긍정   \n","1  TRAIN_00001  이어 ＂앞으로 전문가들과 함께 4주 단위로 상황을 재평가할 예정＂이라며 ＂그 이전이...  사실형  긍정   \n","2  TRAIN_00002  정부가 고유가 대응을 위해 7월부터 연말까지 유류세 인하 폭을 30%에서 37%까지...  사실형  긍정   \n","3  TRAIN_00003  서울시는 올해 3월 즉시 견인 유예시간 60분을 제공하겠다고 밝혔지만, 하루 만에 ...  사실형  긍정   \n","4  TRAIN_00004           익사한 자는 사다리에 태워 거꾸로 놓고 소금으로 코를 막아 가득 채운다.  사실형  긍정   \n","\n","   시제 확실성         label  \n","0  현재  확실  사실형-긍정-현재-확실  \n","1  과거  확실  사실형-긍정-과거-확실  \n","2  미래  확실  사실형-긍정-미래-확실  \n","3  과거  확실  사실형-긍정-과거-확실  \n","4  현재  확실  사실형-긍정-현재-확실  "],"text/html":["\n","  <div id=\"df-1e94f04c-a29e-4226-8655-35aa207f6248\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>문장</th>\n","      <th>유형</th>\n","      <th>극성</th>\n","      <th>시제</th>\n","      <th>확실성</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>TRAIN_00000</td>\n","      <td>0.75%포인트 금리 인상은 1994년 이후 28년 만에 처음이다.</td>\n","      <td>사실형</td>\n","      <td>긍정</td>\n","      <td>현재</td>\n","      <td>확실</td>\n","      <td>사실형-긍정-현재-확실</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>TRAIN_00001</td>\n","      <td>이어 ＂앞으로 전문가들과 함께 4주 단위로 상황을 재평가할 예정＂이라며 ＂그 이전이...</td>\n","      <td>사실형</td>\n","      <td>긍정</td>\n","      <td>과거</td>\n","      <td>확실</td>\n","      <td>사실형-긍정-과거-확실</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>TRAIN_00002</td>\n","      <td>정부가 고유가 대응을 위해 7월부터 연말까지 유류세 인하 폭을 30%에서 37%까지...</td>\n","      <td>사실형</td>\n","      <td>긍정</td>\n","      <td>미래</td>\n","      <td>확실</td>\n","      <td>사실형-긍정-미래-확실</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>TRAIN_00003</td>\n","      <td>서울시는 올해 3월 즉시 견인 유예시간 60분을 제공하겠다고 밝혔지만, 하루 만에 ...</td>\n","      <td>사실형</td>\n","      <td>긍정</td>\n","      <td>과거</td>\n","      <td>확실</td>\n","      <td>사실형-긍정-과거-확실</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>TRAIN_00004</td>\n","      <td>익사한 자는 사다리에 태워 거꾸로 놓고 소금으로 코를 막아 가득 채운다.</td>\n","      <td>사실형</td>\n","      <td>긍정</td>\n","      <td>현재</td>\n","      <td>확실</td>\n","      <td>사실형-긍정-현재-확실</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e94f04c-a29e-4226-8655-35aa207f6248')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1e94f04c-a29e-4226-8655-35aa207f6248 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1e94f04c-a29e-4226-8655-35aa207f6248');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}],"source":["train_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1671751011734,"user":{"displayName":"jaewook Lee","userId":"02714897352724258647"},"user_tz":-540},"id":"fRnnQG288rpy","colab":{"base_uri":"https://localhost:8080/","height":206},"outputId":"8a29291d-6567-493f-dc29-7840eb1398f1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["          ID                                                 문장\n","0  TEST_0000  장욱진의 ＇가족＇은 허물 없는 가족애를, 처음 공개되는 정약용의 ＇정효자전＇과 ＇정...\n","1  TEST_0001           조지 W 부시, 버락 오바마 전 대통령도 전쟁 위험 때문에 버린 카드다.\n","2  TEST_0002        지난해 1분기 128억원이었던 영업이익이 올해 1분기 505억원으로 급증했다.\n","3  TEST_0003  수상 작가와 맺으려던 계약서 내용 가운데 일부가 ＇독소 조항＇으로 해석돼 수정을 요...\n","4  TEST_0004  결국 최근 KDB산업은행은 대규모 손실 위기에 닥친 에어부산에 140억원 금융지원을..."],"text/html":["\n","  <div id=\"df-d13840f2-9974-44d8-9e1c-30201976322a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>문장</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>TEST_0000</td>\n","      <td>장욱진의 ＇가족＇은 허물 없는 가족애를, 처음 공개되는 정약용의 ＇정효자전＇과 ＇정...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>TEST_0001</td>\n","      <td>조지 W 부시, 버락 오바마 전 대통령도 전쟁 위험 때문에 버린 카드다.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>TEST_0002</td>\n","      <td>지난해 1분기 128억원이었던 영업이익이 올해 1분기 505억원으로 급증했다.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>TEST_0003</td>\n","      <td>수상 작가와 맺으려던 계약서 내용 가운데 일부가 ＇독소 조항＇으로 해석돼 수정을 요...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>TEST_0004</td>\n","      <td>결국 최근 KDB산업은행은 대규모 손실 위기에 닥친 에어부산에 140억원 금융지원을...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d13840f2-9974-44d8-9e1c-30201976322a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d13840f2-9974-44d8-9e1c-30201976322a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d13840f2-9974-44d8-9e1c-30201976322a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":9}],"source":["test_df.head()"]},{"cell_type":"markdown","source":["## `유형, 극성, 시제, 확실성, label` 항목에 대해서 개별적인 라벨 인코딩을 적용\n","\n","라벨 인코딩을 적용하게 되면 학습 데이터에서 보지 못했던 값에 대해서는 변환 시키지 못합니다. 이를 주의해야 합니다. "],"metadata":{"id":"yhjfb76DFOj3"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"IAetROKc10CL"},"outputs":[],"source":["type_le = preprocessing.LabelEncoder()\n","train_df['유형_라벨인코딩'] = type_le.fit_transform(train_df['유형'])\n","\n","polarity_le = preprocessing.LabelEncoder()\n","train_df['극성_라벨인코딩'] = polarity_le.fit_transform(train_df['극성'])\n","\n","tense_le = preprocessing.LabelEncoder()\n","train_df['시제_라벨인코딩'] = tense_le.fit_transform(train_df['시제'])\n","\n","certainty_le = preprocessing.LabelEncoder()\n","train_df['확실성_라벨인코딩'] = certainty_le.fit_transform(train_df['확실성'])\n","\n","label_le = preprocessing.LabelEncoder()\n","train_df['label_라벨인코딩'] = label_le.fit_transform(train_df['label'])"]},{"cell_type":"markdown","source":["## 각 항목에 대해서 변환된 클래스 종류\n","\n","* 유형 -> 4개의 클래스가 존재\n","* 극성 -> 3개의 클래스가 존재\n","* 시제 -> 3개의 클래스가 존재\n","* 확실성 -> 2개의 클래스가 존재\n","* label -> 64개의 클래스가 존재\n","\n","모델의 돌려보기 이전에는 단순히 유형 분류가 가장 어렵다고 생각된다. 반대로, 시제 분류는 모델 입장에서는 평의해 보일 것으로 추측합니다."],"metadata":{"id":"YuZqqpCuFs-t"}},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1671751011380,"user":{"displayName":"jaewook Lee","userId":"02714897352724258647"},"user_tz":-540},"id":"bdhODThZXdvh","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5153111d-d548-4d26-f1d8-295d6a64979e"},"outputs":[{"output_type":"stream","name":"stdout","text":["['대화형' '사실형' '예측형' '추론형']  ->  4\n","['긍정' '미정' '부정']  ->  3\n","['과거' '미래' '현재']  ->  3\n","['불확실' '확실']  ->  2\n"]}],"source":["print(type_le.classes_, \" -> \", len(type_le.classes_))\n","print(polarity_le.classes_, \" -> \", len(polarity_le.classes_))\n","print(tense_le.classes_, \" -> \", len(tense_le.classes_))\n","print(certainty_le.classes_, \" -> \", len(certainty_le.classes_))"]},{"cell_type":"markdown","source":["## 라벨 인코딩이 적용된 학습 데이터의 모습\n","\n","라벨 인코딩이 정상적으로 적용된 것을 확인할 수 있습니다."],"metadata":{"id":"8mCSEMK8F3TF"}},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1671751012335,"user":{"displayName":"jaewook Lee","userId":"02714897352724258647"},"user_tz":-540},"id":"uRT7eSgPzppq","colab":{"base_uri":"https://localhost:8080/","height":354},"outputId":"a7cbf2fd-6388-4385-879e-0d9a8d531641"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["            ID                                                 문장   유형  극성  \\\n","0  TRAIN_00000              0.75%포인트 금리 인상은 1994년 이후 28년 만에 처음이다.  사실형  긍정   \n","1  TRAIN_00001  이어 ＂앞으로 전문가들과 함께 4주 단위로 상황을 재평가할 예정＂이라며 ＂그 이전이...  사실형  긍정   \n","2  TRAIN_00002  정부가 고유가 대응을 위해 7월부터 연말까지 유류세 인하 폭을 30%에서 37%까지...  사실형  긍정   \n","3  TRAIN_00003  서울시는 올해 3월 즉시 견인 유예시간 60분을 제공하겠다고 밝혔지만, 하루 만에 ...  사실형  긍정   \n","4  TRAIN_00004           익사한 자는 사다리에 태워 거꾸로 놓고 소금으로 코를 막아 가득 채운다.  사실형  긍정   \n","\n","   시제 확실성         label  유형_라벨인코딩  극성_라벨인코딩  시제_라벨인코딩  확실성_라벨인코딩  label_라벨인코딩  \n","0  현재  확실  사실형-긍정-현재-확실         1         0         2          1           21  \n","1  과거  확실  사실형-긍정-과거-확실         1         0         0          1           17  \n","2  미래  확실  사실형-긍정-미래-확실         1         0         1          1           19  \n","3  과거  확실  사실형-긍정-과거-확실         1         0         0          1           17  \n","4  현재  확실  사실형-긍정-현재-확실         1         0         2          1           21  "],"text/html":["\n","  <div id=\"df-c83af99d-94a5-42b8-b17e-5bc1f4b92740\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>문장</th>\n","      <th>유형</th>\n","      <th>극성</th>\n","      <th>시제</th>\n","      <th>확실성</th>\n","      <th>label</th>\n","      <th>유형_라벨인코딩</th>\n","      <th>극성_라벨인코딩</th>\n","      <th>시제_라벨인코딩</th>\n","      <th>확실성_라벨인코딩</th>\n","      <th>label_라벨인코딩</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>TRAIN_00000</td>\n","      <td>0.75%포인트 금리 인상은 1994년 이후 28년 만에 처음이다.</td>\n","      <td>사실형</td>\n","      <td>긍정</td>\n","      <td>현재</td>\n","      <td>확실</td>\n","      <td>사실형-긍정-현재-확실</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>21</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>TRAIN_00001</td>\n","      <td>이어 ＂앞으로 전문가들과 함께 4주 단위로 상황을 재평가할 예정＂이라며 ＂그 이전이...</td>\n","      <td>사실형</td>\n","      <td>긍정</td>\n","      <td>과거</td>\n","      <td>확실</td>\n","      <td>사실형-긍정-과거-확실</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>17</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>TRAIN_00002</td>\n","      <td>정부가 고유가 대응을 위해 7월부터 연말까지 유류세 인하 폭을 30%에서 37%까지...</td>\n","      <td>사실형</td>\n","      <td>긍정</td>\n","      <td>미래</td>\n","      <td>확실</td>\n","      <td>사실형-긍정-미래-확실</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>TRAIN_00003</td>\n","      <td>서울시는 올해 3월 즉시 견인 유예시간 60분을 제공하겠다고 밝혔지만, 하루 만에 ...</td>\n","      <td>사실형</td>\n","      <td>긍정</td>\n","      <td>과거</td>\n","      <td>확실</td>\n","      <td>사실형-긍정-과거-확실</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>17</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>TRAIN_00004</td>\n","      <td>익사한 자는 사다리에 태워 거꾸로 놓고 소금으로 코를 막아 가득 채운다.</td>\n","      <td>사실형</td>\n","      <td>긍정</td>\n","      <td>현재</td>\n","      <td>확실</td>\n","      <td>사실형-긍정-현재-확실</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>21</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c83af99d-94a5-42b8-b17e-5bc1f4b92740')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c83af99d-94a5-42b8-b17e-5bc1f4b92740 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c83af99d-94a5-42b8-b17e-5bc1f4b92740');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":10}],"source":["train_df.head()"]},{"cell_type":"markdown","source":["## 라벨 인코딩이 정상적으로 작동하는지를 확인"],"metadata":{"id":"YhOeI4FLF-1z"}},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":322,"status":"ok","timestamp":1671751017916,"user":{"displayName":"jaewook Lee","userId":"02714897352724258647"},"user_tz":-540},"id":"7C9W7Js4zuSx","colab":{"base_uri":"https://localhost:8080/"},"outputId":"dd58aa11-8ea7-43c4-bb2a-d2d0af32198b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([21])"]},"metadata":{},"execution_count":11}],"source":["label_le.transform([\"사실형-긍정-현재-확실\"])"]},{"cell_type":"markdown","source":["## 이후 모델 평가를 위해서 사용하는 사전 자료형\n","\n","모델 학습시에 유형x극성x시제x확실성 조합에서 존재하지 않는 조합이 생성될 수 있습니다. 따라서, 존재하지 않는 조합에 대해서는 평가를 할 수 없기 때문에, `None`을 주어서 64로 변환한다."],"metadata":{"id":"EpYxBoUyHsUf"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"eOhwFmeUjE5e"},"outputs":[],"source":["label_to_number = {x:idx for idx, x in enumerate(label_le.classes_)}\n","label_to_number['None'] = 64"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1671751018194,"user":{"displayName":"jaewook Lee","userId":"02714897352724258647"},"user_tz":-540},"id":"PA5mgwCejP7F","colab":{"base_uri":"https://localhost:8080/"},"outputId":"969001a4-00bd-4f9c-f4b7-4696a3c67c52"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'대화형-긍정-과거-불확실': 0,\n"," '대화형-긍정-과거-확실': 1,\n"," '대화형-긍정-미래-불확실': 2,\n"," '대화형-긍정-미래-확실': 3,\n"," '대화형-긍정-현재-불확실': 4,\n"," '대화형-긍정-현재-확실': 5,\n"," '대화형-미정-과거-불확실': 6,\n"," '대화형-미정-과거-확실': 7,\n"," '대화형-미정-미래-불확실': 8,\n"," '대화형-미정-미래-확실': 9,\n"," '대화형-미정-현재-불확실': 10,\n"," '대화형-부정-과거-불확실': 11,\n"," '대화형-부정-과거-확실': 12,\n"," '대화형-부정-미래-확실': 13,\n"," '대화형-부정-현재-불확실': 14,\n"," '대화형-부정-현재-확실': 15,\n"," '사실형-긍정-과거-불확실': 16,\n"," '사실형-긍정-과거-확실': 17,\n"," '사실형-긍정-미래-불확실': 18,\n"," '사실형-긍정-미래-확실': 19,\n"," '사실형-긍정-현재-불확실': 20,\n"," '사실형-긍정-현재-확실': 21,\n"," '사실형-미정-과거-확실': 22,\n"," '사실형-미정-미래-불확실': 23,\n"," '사실형-미정-미래-확실': 24,\n"," '사실형-미정-현재-불확실': 25,\n"," '사실형-미정-현재-확실': 26,\n"," '사실형-부정-과거-불확실': 27,\n"," '사실형-부정-과거-확실': 28,\n"," '사실형-부정-미래-불확실': 29,\n"," '사실형-부정-미래-확실': 30,\n"," '사실형-부정-현재-불확실': 31,\n"," '사실형-부정-현재-확실': 32,\n"," '예측형-긍정-과거-불확실': 33,\n"," '예측형-긍정-과거-확실': 34,\n"," '예측형-긍정-미래-불확실': 35,\n"," '예측형-긍정-미래-확실': 36,\n"," '예측형-긍정-현재-불확실': 37,\n"," '예측형-긍정-현재-확실': 38,\n"," '예측형-미정-과거-확실': 39,\n"," '예측형-미정-미래-불확실': 40,\n"," '예측형-미정-미래-확실': 41,\n"," '예측형-미정-현재-불확실': 42,\n"," '예측형-미정-현재-확실': 43,\n"," '예측형-부정-과거-확실': 44,\n"," '예측형-부정-미래-불확실': 45,\n"," '예측형-부정-현재-불확실': 46,\n"," '추론형-긍정-과거-불확실': 47,\n"," '추론형-긍정-과거-확실': 48,\n"," '추론형-긍정-미래-불확실': 49,\n"," '추론형-긍정-미래-확실': 50,\n"," '추론형-긍정-현재-불확실': 51,\n"," '추론형-긍정-현재-확실': 52,\n"," '추론형-미정-과거-불확실': 53,\n"," '추론형-미정-미래-불확실': 54,\n"," '추론형-미정-미래-확실': 55,\n"," '추론형-미정-현재-불확실': 56,\n"," '추론형-미정-현재-확실': 57,\n"," '추론형-부정-과거-불확실': 58,\n"," '추론형-부정-과거-확실': 59,\n"," '추론형-부정-미래-불확실': 60,\n"," '추론형-부정-미래-확실': 61,\n"," '추론형-부정-현재-불확실': 62,\n"," '추론형-부정-현재-확실': 63,\n"," 'None': 64}"]},"metadata":{},"execution_count":13}],"source":["label_to_number"]},{"cell_type":"markdown","source":["## Dataset & TextClassificationCollator 선언\n","\n","* Dataset은 일반적으로 pytorch에서 사용하는 Dataset 그대로 입니다.\n","* TextClassificationCollator는 모델 입력이전에 형태를 변화시켜 주기 위해서 사용합니다.\n","\n","학습시에 사용되는 Dataset과 테스트 데이터에서 사용되는 Dataset에는 일부 차이가 존재합니다. 왜냐하면 테스트 데이터에서는 별도의 유형, 시제, 극성, 확실성, 라벨 항목등이 없기 때문입니다."],"metadata":{"id":"Xn0JYzRYISHV"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"TMGSW6_eWPfu"},"outputs":[],"source":["class TextClassificationCollator():\n","    def __init__(self, model_name, train=False):\n","        self.train = train\n","        self.tokenizer = AutoTokenizer.from_pretrained(model_name, max_length=512, truncation=True, padding = 'max_length', return_tensors = \"pt\")\n","\n","    def __call__(self, samples):\n","        # 🤗 아래와 반대임\n","        # 수정하기 귀찮아서 그대로 사용 😏\n","        # 수정 방법은 그냥 반대로 조건문을 넣거나 or !self.train 하면 됩니다.\n","        if self.train:\n","            context = self.tokenizer(samples, padding = True, truncation = True, return_tensors = \"pt\")\n","            return context\n","        else:\n","            # print(samples)\n","            # print(len(samples[1]))\n","            x, y, y_type, y_polarity, y_tense, y_certainty = [[] for _ in range(6)]\n","\n","            for idx in range(len(samples)):\n","                x.append(samples[idx][0])\n","                y.append(samples[idx][1])\n","                y_type.append(samples[idx][2])\n","                y_polarity.append(samples[idx][3])\n","                y_tense.append(samples[idx][4])\n","                y_certainty.append(samples[idx][5])\n","\n","            context = self.tokenizer(x, padding = True, truncation = True, return_tensors = \"pt\")\n","            return context, torch.LongTensor(y), torch.LongTensor(y_type), torch.LongTensor(y_polarity), torch.LongTensor(y_tense), torch.LongTensor(y_certainty)\n","\n","class BaseDataset(Dataset):\n","    def __init__(self, df):\n","        self.sentences = df['문장']\n","        self.labels = torch.LongTensor(df['label_라벨인코딩'])\n","        self.type_labels = torch.LongTensor(df['유형_라벨인코딩'])\n","        self.polarity_labels = torch.LongTensor(df['극성_라벨인코딩'])\n","        self.tense_labels = torch.LongTensor(df['시제_라벨인코딩'])\n","        self.certainty_labels = torch.LongTensor(df['확실성_라벨인코딩'])\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        return self.sentences[idx], self.labels[idx], self.type_labels[idx], self.polarity_labels[idx], self.tense_labels[idx], self.certainty_labels[idx]\n","\n","class BaseDatasetTest(Dataset):\n","    def __init__(self, df):\n","        self.sentences = df['문장']\n","\n","    def __len__(self):\n","        return len(self.sentences)\n","\n","    def __getitem__(self, idx):\n","        return self.sentences[idx]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i6-neyFeZ6jV"},"outputs":[],"source":["dataset = BaseDataset(train_df)\n","test_dataset = BaseDatasetTest(test_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zqtq4VReBTCx"},"outputs":[],"source":["import bisect\n","import functools\n","import warnings\n","from torch import default_generator, randperm\n","from torch._utils import _accumulate\n","from typing import (\n","    Callable,\n","    Dict,\n","    Generic,\n","    Iterable,\n","    Iterator,\n","    List,\n","    Optional,\n","    Sequence,\n","    Tuple,\n","    TypeVar,\n",")\n","\n","T_co = TypeVar('T_co', covariant=True)\n","T = TypeVar('T')\n","\n","UNTRACABLE_DATAFRAME_PIPES = ['batch',  # As it returns DataChunks\n","                              'groupby',   # As it returns DataChunks\n","                              '_dataframes_as_tuples',  # As it unpacks DF\n","                              'trace_as_dataframe',  # As it used to mark DF for tracing\n","                              ]\n","class Subset(Dataset[T_co]):\n","    r\"\"\"\n","    Subset of a dataset at specified indices.\n","\n","    Args:\n","        dataset (Dataset): The whole Dataset\n","        indices (sequence): Indices in the whole set selected for subset\n","    \"\"\"\n","    dataset: Dataset[T_co]\n","    indices: Sequence[int]\n","\n","    def __init__(self, dataset: Dataset[T_co], indices: Sequence[int]) -> None:\n","        self.dataset = dataset\n","        self.indices = indices\n","\n","    def __getitem__(self, idx):\n","        if isinstance(idx, list):\n","            return self.dataset[[self.indices[i] for i in idx]]\n","        return self.dataset[self.indices[idx]]\n","\n","    def __len__(self):\n","        return len(self.indices)\n","\n","\n","def select_split(dataset: Dataset[T], indices) -> List[Subset[T]]:\n","    indices = indices\n","    return Subset(dataset, indices)"]},{"cell_type":"markdown","source":["## 학습을 위해서 사용되는 Lightning 모듈\n","\n","Lightning 모듈에는 training_step, validation_step, preict_step 등이 존재합니다.\n","* train_step 같은 경우는 학습에서 사용되는 부분입니다.\n","* validation_step 같은 경우는 검증을 위해서 사용되는 부분입니다.\n","* preict_step 같은 경우는 최종적인 test 데이터에 대해서 예측을 수행합니다.\n","\n","학습에서는 validation에서 f1score가 가장 높은 모델을 자동 저장하도록 합니다. "],"metadata":{"id":"YbSj82vtJkNp"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ULvdNPvI_1AA"},"outputs":[],"source":["# type -> 유형\n","# polarity -> 극성\n","# tense -> 시제\n","# certainty -> 확실성\n","class ClassifySentenceType(pl.LightningModule):\n","\n","    def __init__(self, model_name=\"klue/roberta-small\"):\n","        super().__init__()\n","        self.model = AutoModel.from_pretrained(model_name)\n","\n","        self.type_classification = nn.Linear(768, 4)\n","        self.polarity_classification = nn.Linear(768, 3)\n","        self.tense_classification = nn.Linear(768, 3)\n","        self.certainty_classification = nn.Linear(768, 2)\n","\n","    def forward(self, x):\n","        tokenizers = x\n","        context = self.model(input_ids = tokenizers['input_ids'], attention_mask = tokenizers['attention_mask'])\n","        context = context[1]\n","\n","        type_hat = self.type_classification(context)\n","        polarity_hat = self.polarity_classification(context)\n","        tense_hat = self.tense_classification(context)\n","        certainty_hat = self.certainty_classification(context)\n","\n","        return {\n","            'type':type_hat,\n","            'polarity':polarity_hat,\n","            'tense':tense_hat,\n","            'certainty':certainty_hat\n","        }\n","\n","    def training_step(self, batch, batch_idx):\n","        tokenizers, y, y_type, y_polarity, y_tense, y_certainty = batch\n","\n","        context = self.model(input_ids = tokenizers['input_ids'], attention_mask = tokenizers['attention_mask'])\n","        context = context[1]\n","        type_hat = self.type_classification(context)\n","        polarity_hat = self.polarity_classification(context)\n","        tense_hat = self.tense_classification(context)\n","        certainty_hat = self.certainty_classification(context)\n","\n","        type_loss = F.cross_entropy(type_hat, y_type)\n","        polarity_loss = F.cross_entropy(polarity_hat, y_polarity)\n","        tense_loss = F.cross_entropy(tense_hat, y_tense)\n","        certainty_loss = F.cross_entropy(certainty_hat, y_certainty)\n","\n","        type_ = type_le.inverse_transform(type_hat.argmax(dim = -1).tolist())\n","        polarity_ = polarity_le.inverse_transform(polarity_hat.argmax(dim = -1).tolist())\n","        tense_ = tense_le.inverse_transform(tense_hat.argmax(dim = -1).tolist())\n","        certainty_ = certainty_le.inverse_transform(certainty_hat.argmax(dim = -1).tolist())\n","\n","        labels = []\n","        for idx in range(type_hat.shape[0]):\n","            temp = f\"{type_[idx]}-{polarity_[idx]}-{tense_[idx]}-{certainty_[idx]}\"\n","            try:\n","                labels.append(label_to_number[temp])\n","            except KeyError as e:\n","                labels.append(label_to_number['None'])\n","\n","        f1 = f1_score(torch.tensor(labels).to(y.device), y, task='multiclass', num_classes=len(label_to_number))\n","        # print(\"😂😂😂\")\n","\n","        loss = (type_loss + polarity_loss + tense_loss + certainty_loss) / 4\n","\n","        metrics = {'train_loss':loss, 'train_f1score':f1}\n","        # metrics = {'train_loss':loss}\n","        self.log_dict(metrics, prog_bar = True)\n","        return {\n","            \"loss\":loss\n","        }\n","\n","    def validation_step(self, batch, batch_idx):\n","        tokenizers, y, y_type, y_polarity, y_tense, y_certainty = batch\n","\n","        context = self.model(input_ids = tokenizers['input_ids'], attention_mask = tokenizers['attention_mask'])\n","        context = context[1]\n","        type_hat = self.type_classification(context)\n","        polarity_hat = self.polarity_classification(context)\n","        tense_hat = self.tense_classification(context)\n","        certainty_hat = self.certainty_classification(context)\n","\n","        type_loss = F.cross_entropy(type_hat, y_type)\n","        polarity_loss = F.cross_entropy(polarity_hat, y_polarity)\n","        tense_loss = F.cross_entropy(tense_hat, y_tense)\n","        certainty_loss = F.cross_entropy(certainty_hat, y_certainty)\n","\n","        type_ = type_le.inverse_transform(type_hat.argmax(dim = -1).tolist())\n","        polarity_ = polarity_le.inverse_transform(polarity_hat.argmax(dim = -1).tolist())\n","        tense_ = tense_le.inverse_transform(tense_hat.argmax(dim = -1).tolist())\n","        certainty_ = certainty_le.inverse_transform(certainty_hat.argmax(dim = -1).tolist())\n","\n","        labels = []\n","        for idx in range(type_hat.shape[0]):\n","            temp = f\"{type_[idx]}-{polarity_[idx]}-{tense_[idx]}-{certainty_[idx]}\"\n","            try:\n","                labels.append(label_to_number[temp])\n","            except KeyError as e:\n","                labels.append(label_to_number['None'])\n","\n","        f1 = f1_score(torch.tensor(labels).to(y.device), y, task='multiclass', num_classes=len(label_to_number))\n","        # print(\"😂😂😂\")\n","\n","        loss = (type_loss + polarity_loss + tense_loss + certainty_loss) / 4\n","\n","        metrics = {'val_loss':loss, 'val_f1score':f1}\n","        self.log_dict(metrics, prog_bar = True)\n","        return {\n","            \"val_loss\":loss,\n","            \"val_f1score\":f1\n","        }\n","\n","    def preict_step(self, batch, batch_idx, dataloader_idx=0):\n","        tokenizers = batch\n","        context = self.model(input_ids = tokenizers['input_ids'], attention_mask = tokenizers['attention_mask'])\n","        context = context[1]\n","        \n","        type_hat = self.type_classification(context)\n","        polarity_hat = self.polarity_classification(context)\n","        tense_hat = self.tense_classification(context)\n","        certainty_hat = self.certainty_classification(context)\n","        \n","        return {\n","            'type':type_hat,\n","            'polarity':polarity_hat,\n","            'tense':tense_hat,\n","            'certainty':certainty_hat\n","        }\n","\n","    def configure_optimizers(self):\n","        optimizer = torch.optim.AdamW(self.parameters(), lr=1e-5)\n","        return optimizer"]},{"cell_type":"markdown","source":["## 교차 검증을 위해서 k-fold 값을 5로 설정함\n","\n","* 초기 학습에서 오류가 있어서 1번째 모델 같은 경우는 별도 코랩 창에서 학습을 수행했습니다.\n","\n","모델은 \"klue/roberta-base\"를 사용했습니다. 이 모델을 사용한 이유는 제가 대회 참여한 기간이 하루밖에 되지 않아서, 큰 모델을 사용하게 되면 학습 시간이 부족하다고 판단되어서 작은 모델을 사용했습니다."],"metadata":{"id":"7R1gjcsQKfWu"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5_w3h-gYVxmQ","executionInfo":{"status":"ok","timestamp":1671742881023,"user_tz":-540,"elapsed":7732411,"user":{"displayName":"jaewook Lee","userId":"02714897352724258647"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["8d5c25c9727a4e5c80d649b4ceac5d66","8e445e973f8b4f258371b843ab681b54","588dfe9733574412afef77d73d60b423","1745f65ac5df4032a6ea4ccdf5e5fc1c","b457fd4b2ed949da984ba5ce236dec1d","cc2309ce14ac478bbbc9f85cbee66f24","caa7f2a87e41422d939844a13314d7fa","f4275d6376a6448bad3a54b7934dbf10","0e6e3cdf22184acba6443d6c73c4bcf6","021d3d2bb5d14e0383d44de6dc93e3dc","d9020dea4d344bb8b627ea24966f493a","de755568ce7d40248a4a29b528ae44f7","c5d58a19a5244f3883692c764d2bc50f","437bac47f4f442d7bfc7b13a76d7a15c","d826b22c6bda4f7db004376174a81298","4c055f79eb51429e9093ac38343da9e7","5732cbc752e34274888a9d2a49611ff7","1dd176499e734bbea0680410f1ee1511","ef2498dbc8f94137988f9753eced4c83","1bb37fcb05104da798818a3d4d9e0f4a","7185f38090744522a37f07f6eb5d92ff","af03b6ad90f144c0ad6b247cfdcf501a","ddc43e745f444cc1b664b7188be2c4b2","ed40c11868474bc6b53afaae010752c0","639bdf0b65be42689af3f870f4b5417e","4462034c45e44e53ae3fc2e8daee45aa","646646324f8144f59924eeb0fc1788dd","cb08143f1aa940648894ce9c3594d7e4","275cf0d1aede48daa8b73e3f541794e8","2c9cfe4ab6f24cd2b036c79fda473450","c6fcf7a947944f708f1257db6f4146de","ead577bab41241879cc1858d0c8324a9","314c7288241d46e88d21b67901f47031","daa6ab8ccfe844eca6f4b6de0f780956","843077417be14d2ca7da587443d10f62","d004da9a3f5b454f862d798bef793a75","e72becf055664badb646b529981ee264","7e03be2bf0b146869bd3567ad56f7937","5a1a064919294abfaba367de779fd080","ac2ea264ce194814974aee774d2de15b","7e87c8a4ddbd484cb4554b53a4d3e692","da9d6a6ecb4b43739857db6733be8d71","7ba338b9d1b3499b9b4c933b66d2aead","53d13bd076f44ebeaa8956b3c2c81d9c","4c10c24eecfa46d0b9b6b65b6700e951","126ec3fbccb84ed7aa32914f2022a1e4","58b4244b5c734029b0bcd8589458430b","ced14179eceb472f90c1f1d7152cdc6a","054b34d36ba247ce90965b87a5996d67","7b11da65edfd4f13ab323537ad726fd5","ff52bf1d0ec041759fb23ec84e0bd85e","aefe6a774bdc4e2e8b02ef045ae70dcc","2c78b10738904f47a11c6b9b92d04062","6e39c117e0434c4fb86f84239a90419a","1af5e22197754a20b58ac2d53bbab2bf","e713907722744a4b9a901ba81a41a64b","0c872b8d3a01491d9d78f75492ac295a","8ae122a858f24fe7826cb3452cdf32b9","2d2ebf0741bd47e39db9db7c4a40b426","f7007e7ad7b948d3b2ffd861fcb7575d","c4c349cc1c95411981585d903f45a8c6","7332b8ddbd30449cadc539c35faf49fe","a8711f15094c4298a0e04d9712cae18a","fb7e6911a4314189a8d25d09f20f3ee1","75103c076cdd479b837a0c11c2ca2ad4","fdb1325cf71d4fdf9ef5c606dfc6495d","d32fd66c8e1a49cfab20850671ba1e2d","8b595aad833248b796f38ae73783bbf3","18456252468a480884282e25f770818a","45ee6a105c0946ccbe98c2e278d7b71f","e066477ea6944719b34b2555de9bff91","253860bb16374386875c5c52f3079245","ed881c08f22940788ba90d6ece995eb3","c58f73b2ef244340a947b214c423aa49","51e46716bf9548e883a71ff5748830ee","4404ceab78154adfb4a4063de2653413","a6c0c502ae6d487a86d143ed4fd5dbc6","3a7303963f6d49f1a9b56611e9c0137e","02befc15789b47a8ae89f4ce905ceb12","4eca3c504ba247e1bac017ac63952cdc","7a6d8f559b5f426ea73c32d52549b9e4","cf270babf027419a8911323daf986e1c","0992f18680c0424799f7a9cf66209b0f","cf3bf770f873495e8d92b5b788bf481f","ef0047f7abfe4db5ba07b850740f8af7","38634da3880647d5872348445a6cad5d","d33c282951e549eea9cf965c2868406f","f4bf47e0fad4443b9b228297c35db478","5557a33be5664658b29bec6142ecbbf1","e546a539c7f04d418e87a027855ed7d4","bed5ad42d6704465bc8dbd5a313c042b","f81ff19038cd4e35a0f946b2d30db819","826778d839884b92815079571080659a","a89fde61d6614059951a479169a6ec78","5cc0d73717d04760b0b9f4083be30071","3aad0fdb0c9b4f0590cb54b06166dce9","6d4ed0e235774c2d9689044d68406a21","9fa5614162de49d2b9e6d8412c768429","a4adbd242ed84b3aac00f7f12b6cd262","d047fd12b75346e8850693759e123cdf","4e10e7eccebf45dcb0f639d63470cad4","92392222ef37447696669a7ef59f23d9","27c4f65358a647bd85ca9d9e7cd9f740","36313767dc5a4c95ab57f110d8fc0dbf","8d9eea4134ea487a8173ae5de4e02a01","a8d9f751b5094feb87c80044d012dd86","86adc492d5db40a9b359da765fa90e95","6448f283f398435fbeb2f092e3a149e9","dc48a67e67fd4f2183c453526722b187","086afdb67e2a417a950a340b16bf75a1","2b2afd5fa9014ecea5cc84070cc8c8ec","8974622f94be4b77b47468ca6e8c8d8c","6c0f4406bb5545fb840c54b1bb4fc03c","fdacfff8b3cf45ec987bb79272b090d8","e6d7d76f84a549899ce5c5accf272306","771ef295ac1942ddbb49a466a2bae90f","7849e320901e41e78d775d3072bc48e5","d78adb6a4734477b9772373a8dbd2c3a","3e26fae3ce4c425fa8c267a18c5ab316","f8ce7d84d0a74fdd986921372b5cc11e","99df9faae57048f986ea8c600c47bb35","be939b07a14a420281ae64cd9c4ac597","0ecceb5975c04d758b213d5a61f81d48","974d458cf13f43ccaf9e42c7aa6f4a19","b43f75c39b3e4d7a82bfadc218dd4b89","c105e11cf0ef4ee79c01182214a3d3fc","11e5fe47027641bfb61482b5637e14be","5ce2887d27b84a8cac243cc145c59ccc","e8a98bdb7b7b4718a32309ce00482738","b55765b28ed340d8bff755553e8de6d2","9443889b69104742936ed78d1ce284ce","1cf8b89e125845079454294cf351da5f","57dafe9a5a1c43e98cf9d1dd0b28e05c","d853882553034bc0bbf92dc9ebd741d3","b918f198e1e0411791b45484d6359033","3eb25fe537f6438aa821fd491301d8da","ba485c552c0e4a469c5410888f67d3c5","416a29a4c0be41baad913357209a4f02","d549aad15b324bf4b3fbc8006936e347","840089298cd24843b75ed91d5b66746f","6f23663486f44cfc8b349343916de71a","6ed4fc7393944abe835bcf1ea8f80b0b","041ee7b00f9a4f7bb6bfc18c10b0dfb6","0235e6a02fb647abb4519ce3d67017e0","4fb62a4359404f64834aa9fee70d493e","a900781fa1644216bc72b0d4da2180f3","8837f061ae75411793d08581985c03d9","3bff8f5e7af8487e87101f2bc9134245","717632e5ee9c4042b57e8390603ba984","89da4848e93e4b738169047b6066b2a7","d7e0a21b3810442d94fc2061c2fcf4cd","7915d822e7ed4dafadd551619e1d68eb","c80dce69fa244008a168c235d1b6cfa0","df4b5e5454d34137b0e40eedd840c209","34dfa9fdb8ab404b9989e766b89f8eb3","76407b3db3e94bdd889dc42efbeb1def","6a53044a5331484caec0f3fbbe3e8652","ddaeeef1d44744f894d2f813a12284ef","0210e781b24e45a59675f216961ebe85","c9285e2db6234bddb74905c85b3406ed","2628af6f053746bba4bf331084535a71","554f2380c4a741ee984542c5b07c8476","0f582a7160814a548811cc3b940e753b","ad71aaa91a73414d8a1b16200096931f","449e159345a04ad0be32de6842897ae2","b839d07a5c3d4ecd90989bbfead9260d","bfa832ff773e44a8a0684c8eb026ae91","7e12cd8045fb456b91c93c7da1972870","b6d6162df30d49d28c1b35dded75232a","ee75a4ae109d422cb10516695ca428c3","c598b5e4f6ea4a759ff5d8587b5a0889","b68c0077d41142fe8ae24b32eff77635","95d8bb4dcfbf41e5ae0211d63b60d67c","ea6e8c9764af45898af63289da86e23c","fe16fbbf54074888a830438c7b643d78","5291d8d89dc9461d96f0214550456875","12093ea681bd48e89ba10168d3e9d715","0b2bb8efc4bc4a399db04ca0a0b7f4f4","fd906254a1ff4effb856a5cc08e115ba","10d0038b29284634b611d111b168c8aa","be75a41dc33b4cce82f63ef83b981766","7bb59e12e78446b5b936d1707dd9da25","f3d2d4e90cbb46ba8bb046c935c8a591","f1b3678d2ec54451ba8f37e4c2672641","cc980821af2040c3bca5e994e14028b2","652e07e7bbba48478e100c40e04909f4","b28f2e4d5acd4370a7cc4abeb6fcd23e","b36783aba454422191cb5d7e447e54cb","ba5c021e08e94923b02e0a5098f52ae7","7957c1f4a82b4deca11167538f354852","acba1b960c554ffcb9075556ba29eda9","d6f0fbc6db5f4f97a72d63a7344e2ac2","0c5db377d91e4a618e16c0fc89dbe1cc","b5349da827d045eb81085e94bd814ef2","b748228240354b6c8a699d8ac12c89e7","07bfe496dcd94229a8704504f31ed47f","94219954a94949b2bc459349a68c049a","e2b3da88e7bd407d8632844a6744211a","edf19d410118400ea9ae52851d3a6f66","e45567d228304c59990d8120708d248e","dbb4a5ea529e495b950c3a979dafcfc7","e65ed732a28942c69485dc270e9df3c1","67051291633e496aa8e66b8d71038e57","ffa3d24003264492a79e40967658436d","9a93b28ab2b54d06b6a97fc42845150b","91ad16680f96404d9634222be37e65fe","e37568f35e654866aab69b9550a72ec0","56886abd29c245408d27071b6afa646f","6be63ff5f223491db79f389bc5e36ef9","ecba436dafc44017bb73a0d6dfe97119","c306ecd912464a408094c0c2d6b25ec0","b9715daaf18f490b9dcd32ed02d9d15d","cdd97f5722da4e5b825fac6ca0566a42","546ca80197cd4f0fb47ae285c4aeb17f","67e58c0a064847b1a12209257c65f2a8","e45a58a45f574b0ea93e653a1a4d199e","379fb91aebff438bb73028b586615f39","774113ff8b1c46ad854917c3993bc969","2b95a020042647e08982c3bc170ef169","29012642f6f148e7a0dc0af832b25d95","415606cc48be4922b735da9e99199420","6bad437127114f6eb80a5d40692f7439","a36a16b26867411db707b861f41231e5","4dde7840ed684160813647d74a983256","592a90e268554517bc576c71433ac83a","d0b41e7a98de4631af06acf8bba7e61b","9a2d1bed48f042deb8e999065e01bb53","7fcb4633b2004f6f9188d88501a46037","bf103fb3ad59403fb258be5e8b7d0593","60c5ee1a81754aa7b7c6eb09633e0d08","365bf3a26f1840abb7a81ad99f44478f","2fa4aae254da4884b1a1f01ae6ff92e2","2b80574aee35454a8e19285771449b27","b8a4556982e547e9a3edaef186bed3a2","a6ab16a6ecc149be821e63c932689563","90e19d06d0ed4071a378eb6139f468e0","14590cbc548a4226ab3cc184394703f3","bfe5f304a2bd461290051760954aa4a3","a117af57fecd46d1892cd235bbcf35a3","ec03850a6a374271a13db38adb87c812","795e5e02f4cd4e969123484add9459eb","6e8af86b42824a02a21b5511a5e11557","81dec08dc28d424db1f7032372ce6916","7da32dc7bebb42dea33a94738bf84400","7fbd3e374e0c4857a4c9d3f919f6d543","dad75c01dc11494dbfe0e14e78b1e3a6","8f10b81888d348689f2d69859429b548","aca0d4edc35d497bb2a3447307101f95","ba3758d02c3e4f9fbe723914f8db1fe8","615a5fec9fac4bdb8ea7dc80701498b7","ba9ebe3290e24a29befba09e32ce7a3b","5c39b7c32f2f4f6abc47904b85a141f4","4d87fdaca44f4483beaa1ac20d32a94d","63440ef5cf6f4b82abdc5afe3f4c1b2a","61ce227432914ed7bfb89645ac6e01bb","3b9478d618fe42fba12921722031cc47","54820f0c149843fd96c77d443fddf64e","6e6511cdcfda4070b19162636d98e881","ce502e503803415d97db16001276ae73","373db8e75c5c4ddd9fb8ebdee9848caa","83c13e342d0244359a038dea020516dc","9f6ad4d22536440db702c9d9489b2994","9026e0a5d03b46e38fd9a8eabcfba18c","3ceb02e0ced64d779d0840009035e61e","00fbe7d0d7f849b49c3950e80c26d6c2","67b98b22b8f5483a8e11bad80319cc7d","c38c1a6b6b6049638c25e3950b10f94b","baf094b05dc64b5195e7d8dbc18ec8d2","0a55799e1f064b2d96fb4ec03431f227","e2b444ab2bab41419a0d71e943101a9e","2dbebdbc54484edcbe5f97df0f714cce","d2fb5ea3053b4b60acd1fc2df25d9397","966fde42e8d0426e930d1f2e277fa02e","935454fdaafb4cd0abee570a4f3857b8","caacb111dc6d412eab166d6f985f6705","44cac819299a4ce1921ac884201fc328","efde64e44f334d3aa7a2be3c91476170","8505700a3b904602a3af64daf76dc404","c44b1869df264c0a92a14cab538fb7ce","10a784631ce244e19078cba1946aa2bc","650ad6c781ee4c379afc10867d8c3825","1786f91b5dc742329eb9dda0a19ff6d9","a7559ee00f7143b79a80ae53f4d80cdd","32fd30a38fac46729520b5cba2bf6fdf","76099a7c75a447f98c7ce9b26f93d71e","98863ef140294a77aa83b88cdca61829","9abebb79a08848eb849a2585abb620a5","3b7df3cac894434aaa0454b2ebda0d40","2c0d571c151845e880bb97d2b668661f","5aef012b74c94319b92719f05314a88b","adcb8ee19c2f420a9af1f7acf78abe0d","33efff51d5754b29944ab3f00c2d568d","f7593315f36e4d3bae88d79a02ce618f","c37a259b60a14de980af0a13e8dfca12","c785cbb00d05468685f7206b5b007f03","b52a6b226d3d47758b9e4f3378a95ad1","b14d8c3e98ef402183b86e527d236c29","61bb9caed5fa4de0b73f8953b178e8f6","9b50e39f2a0541c79818e4e96f723853","d44378ae2f5749a3912cc2f8ffcbddf6","2676e14557e34d09a75df7eaf93a7017","5884410d216b42a4955572ba7cd2a693","652cef98a89442eabf2d02e1db58bfb7","8d22132a40fa48809f70e0b08adccd93","fb161895c37e4697a4b5101f5d00b052","6c817b5b8853425ebf22ea86dff0c459","051e5f8e5b4a49db8a786d200731a533","de7b9b9cad8f4effb45b4e68a4089600","a4a2efd426e7484183ca7eb020adc881","26e10d77cb5942f79b56bf6d99f9faf5","1bbc3b5ab7ce40fbba6a9505af9b3d31","f4ee3e5e8fee4dc9b2cfb26dcc300f78","de0cac4524474dbd9130cfb3bb04dc32","d492f520cb3c4f6db48caf23d6888cb3","dd6935f1d10e459bbcd6476f82415f34","04c0fc8bfe974a40b757154a35b6bd49","44242c59b8744b4da23d088956d09e7d","200417fcda424d529b730bcf48feb051","e6f603f59f594139b9dbde3593d6cd55","849b2c167f71417bbd6d1d5a59b13a8f","99f50a5555244d2d96baf641ebccd1e8","e5a6475047a24d2fbb2c6e42660ecbc3","2e5d927959f94ae38de6fc7cfbb3a368","ea59932610164c139331f151308b83aa","c859d5435c71405d9657ef41a08f74dc","f752f45dd82847a892142fb6e6f207a7","f22886454d284ce4b37b286a3aab1fbd","f9c7e0c371e64d2cbeac83aa74662a14","c491860d92b946ada64406c3ddd14fa0","4a334002ed60473f88fe724427cb0c4e","f54e21c97d414d828bac5d52fa155fa1","c4512a22a7dd4412ad8cc9db18c677ab","950bd7ffd88c4e9ba1529bdaded4037d","deb65e15a26643b78748307c3f68f0e3","6139ed78292c495582e5db77aa74f8a9","198d804a8edb40d78ca9589f9efd5cf5","9c833a5f909e4f52ab13b51f0e5af79f","fe2c0d7c87f84b7e8c034959be66550b","12e4ee7710ee401688a741c2a44f7f7e","d2f88a3f0c624b53ade204d64abb2d0a","66bef1492db74a9c9889342e38a6c912","c2206d125f63472abc248611b6f5921d","ea9ba2dd20ea428591e82baccc05947d","193bd00147be42fc805387420c43c933","6f5b0d5868e24b36be51f8c750bd4139","4b36692fd8b84db6a7559e6cff2be03a","66428d8d151348ae897848bc18da32b0","b6ca404dd2da405188306682f2bda00c","c1cdf5efa2a841439064035ad8270be9","721bd223788647689a8c9c53ff9d574a","301232d37e774ce383282b61677e3794","b6123eb47256410c803c4cbe53b06ed0","b8be18051d844017b2a324e1ce20655e","86aa89bc83f14d5aa59b34dd58c0ac6e","78e244327cf144058ff816384b2e9643","e01a830d022e41008f2f8b4f8a208265","7e172bd746384a9785560f50f81de03d","c08310fac82348c1ae30b71de6dc6ed1","b444b82e20234b929fd318b62955efa4","f110e005b53f4779b810694e5bc921fc","ff2601cbf89747758b7eb2f6d2e38103","0c5fe89ae08e4143b49d15e3ca9f4a48","cfb313282ab04adfa3c17e54548c5a48","1532d399db0a4bba871314a2289b3178","b8f59405d9a245c8b6b6dc415008e300","f255c7203bdc4c22996a2c14805d79de","7d6c1fbd6f8b4b3a9f0a0c529c817ebc","a012f3674d3d437cb025ef2d12c52b89","d25c754b7ab64c599d32ec1527b0cb2d","afe4ee1a58984835829d6bd4bf4948e3","cfdd8f0e0eaa4facb27073311719468d","dfbd3bbe5da0406e9a33b04caba339be","e411eeef5fba4c73a5f083dfcc2c0962","0324904383ee4ef6b8fcac91f3daa4ba","0f18d438f0f4488d8c47f6008555eb4f","46b667ad4a0e4682a168f00515ecdce6","f47dbc6c77274ce898ad1ccb38e8cc03","8d4a12f12bc9493dbf9e6cfdde593895","70dde8aa128c46ab8cd1232bea1ade74","0a52993dbf3946a2ac743f1ee20237c5","3fd12a05ab674d01b6959c2567b2b2fa","7a05af9370c041f4b19bcc39f24a5268","1da9b2963b184d0bbfb4233b43e26c2b","adb1d63fe9274fc9ac5a75a73fb7ee9e","93e06fabdf094832813f2483ca33cb60","002f897806ed4bb3bc63218b2fc8d9f1","60656d667b874078852ef59d07429fcf","4b1096d635734b55bd710ad4e1838211","6b611f2751cd4a23bb2a817463b3384b","df53b01d1f4842408a271388d6a4c7d4","118152a319384e31a7281747b2c4f945","334255ef599c4187aef60b439cf48631","f34fdb23b1cf42d1a12fa5328c88afbc","fe649ad33988455eb50942c6a0834101","c67c0238acd842858745b024b06875d6","587f791cb58946dab93ad9ddd97eabac","4812f150f1954a00b574a0b2fc2f7250","72b4184b03ac40bab60773ebd98008ea","537de54c0ec746e58c7cf2c9534e2eee","5fcc46ced83f4fb3a46200ace673c3af","360e93354c9e42248e182b22208ae7ed","a0d2a450278248bd9fba403052261b8a","22fc69488a57459783deb7d647605cce","ae4e795ac6584acb8079b6fe821f7d7a","3af16dba6f6d4721ba305704f637db8e","f4dce922a6dd41e3889ff7393fd17068","fe4868469eaa414db5fe5fecd97f426b","606f79e8ce1f474c8a33f43d2ba57421","9d105ecbe49f4cc680b616203e0fde80","8f0dcf7b4f674e66ade69448afe5855b","ee4f559c4faf4565a884d9f14b2751cd","f843429c42f84460a5672d74f1e9efdf","767548881c0a451fb8b3a5ea315fbf84","4b7a09a083d54975b1358e5bacd63659","e90604a9bd47444b9954743aab5d0f7a","c9c77eaab082456b823a2c8ade497178","cfe91652428041bdb26f2058c8a945d8","0804b21682474a48b984318edfcfe86a","d64ea394ffd4422ba24da1d6b897f838","3df87139ea5141398d7bd78173a141a5","524291f3632f41e1b4d6c2dba5280c7f","eb4dcd032de144d4a1707b2a5b058069","e1854afd975a401d9e79b9b4af32ced8","a772e5fd925e4a479a0a8016d15b68ce","04687905a465485d9a974cd1ef870a5a","57461fda410e4e1f9306009aa589bad1","fa222b448d644e678f63c86f9bee3545","1a2b8d02ad904fcb99d8ac0f9dae7bbe","bd89e53d2bc04ea892b68b9c335c3322","cb3e2f3915fd4d6f9d7151ced03e4cad","55da0b0a15474eaeae4a5973c3962b4c","9698c83a952c42e9b8cac906fc8f5d34","a0da8634f0ad42408edf4eb397dedb2f","f05a7a3fea33457e8705df378fa484e0","d9e3b4c4fa8d4210bdc91e4236c4de51","e65c5694a526424197310ea3dd9101be","88521355ce034f039b69759cbfe06b8a","ffe86d70bc2141dbb82fcd4d72bbeb54","feba3287d89e4fe6836b8deccbc35d61","68ae146b96c94085957ab57c92c6a2a9","9d4befc6a6c84b2c919ef6eacf946144","6647559752be4d3b89b16b74fe36b7eb","b4319c0a64bd44a4bf38452343735ef6","890b509d23cc4689a3248e9af3ab953b","f3eac3e0598c4b258bfd6c1bbc0ec220","7cff7bdf0e6545329f7ca5d4d30be5a6","9696d7dc77474ea69ecab4cf2fc7c35f","dbfb511111c5451bbb695bbd349f27c7","a9e12629b38b43709be50cb606b6c39e","1100f211c5c549a4a167b5b560c90625","480894b2862141f98f82985fe58917c1","d42523c0e9b4466b9b5b52b126b6ccb9","44b72664f29244fc9fee7eb111d984bf","c7b7fcd9c26f48819e3752853cbff9a7","b04853b327f543a1a9f1bd79ebd3cb16","3e18a08752a94d30bfbd9c6df4d8c84e","4ae7f2107e444ea59fcf96cb2da29a19","d0187f3597aa4fe8be0b6ec9047a5559","33cddd21904a4f3895dda339c4bafee3","40f71d55b7ee4d788e223b38012c8ba8","f6ca00f0230145528e1da5f80ec41ca0","78584c54e0a54683a899cd8973ada8a8"]},"outputId":"f974cf04-153a-43aa-9093-09fcfa5c97d6"},"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name                     | Type         | Params\n","----------------------------------------------------------\n","0 | model                    | RobertaModel | 110 M \n","1 | type_classification      | Linear       | 3.1 K \n","2 | polarity_classification  | Linear       | 2.3 K \n","3 | tense_classification     | Linear       | 2.3 K \n","4 | certainty_classification | Linear       | 1.5 K \n","----------------------------------------------------------\n","110 M     Trainable params\n","0         Non-trainable params\n","110 M     Total params\n","442.509   Total estimated model params size (MB)\n"]},{"output_type":"display_data","data":{"text/plain":["Sanity Checking: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d5c25c9727a4e5c80d649b4ceac5d66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Training: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de755568ce7d40248a4a29b528ae44f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ddc43e745f444cc1b664b7188be2c4b2"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.callbacks.early_stopping:Metric val_f1score improved. New best score: 0.752\n","INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 414: 'val_f1score' reached 0.75242 (best 0.75242), saving model to '/content/drive/MyDrive/Colab Notebooks/DACON/문장_유형_분류_AI_경진대회/fold1/epoch=0-step=414-train_f1score=0.7058823704719543-val_f1score=0.75.ckpt' as top 5\n"]},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"daa6ab8ccfe844eca6f4b6de0f780956"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.callbacks.early_stopping:Metric val_f1score improved by 0.008 >= min_delta = 0.0. New best score: 0.761\n","INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 828: 'val_f1score' reached 0.76088 (best 0.76088), saving model to '/content/drive/MyDrive/Colab Notebooks/DACON/문장_유형_분류_AI_경진대회/fold1/epoch=1-step=828-train_f1score=0.9411764740943909-val_f1score=0.76-v1.ckpt' as top 5\n"]},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c10c24eecfa46d0b9b6b65b6700e951"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 1242: 'val_f1score' reached 0.75998 (best 0.76088), saving model to '/content/drive/MyDrive/Colab Notebooks/DACON/문장_유형_분류_AI_경진대회/fold1/epoch=2-step=1242-train_f1score=1.0-val_f1score=0.76-v1.ckpt' as top 5\n"]},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e713907722744a4b9a901ba81a41a64b"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 1656: 'val_f1score' reached 0.75635 (best 0.76088), saving model to '/content/drive/MyDrive/Colab Notebooks/DACON/문장_유형_분류_AI_경진대회/fold1/epoch=3-step=1656-train_f1score=0.9411764740943909-val_f1score=0.76.ckpt' as top 5\n"]},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d32fd66c8e1a49cfab20850671ba1e2d"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 4, global step 2070: 'val_f1score' reached 0.74607 (best 0.76088), saving model to '/content/drive/MyDrive/Colab Notebooks/DACON/문장_유형_분류_AI_경진대회/fold1/epoch=4-step=2070-train_f1score=0.7647058963775635-val_f1score=0.75.ckpt' as top 5\n"]},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a7303963f6d49f1a9b56611e9c0137e"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 5, global step 2484: 'val_f1score' was not in top 5\n"]},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5557a33be5664658b29bec6142ecbbf1"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 6, global step 2898: 'val_f1score' was not in top 5\n"]},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d047fd12b75346e8850693759e123cdf"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.callbacks.early_stopping:Monitored metric val_f1score did not improve in the last 6 records. Best score: 0.761. Signaling Trainer to stop.\n","INFO:pytorch_lightning.utilities.rank_zero:Epoch 7, global step 3312: 'val_f1score' was not in top 5\n"]},{"output_type":"stream","name":"stdout","text":["2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name                     | Type         | Params\n","----------------------------------------------------------\n","0 | model                    | RobertaModel | 110 M \n","1 | type_classification      | Linear       | 3.1 K \n","2 | polarity_classification  | Linear       | 2.3 K \n","3 | tense_classification     | Linear       | 2.3 K \n","4 | certainty_classification | Linear       | 1.5 K \n","----------------------------------------------------------\n","110 M     Trainable params\n","0         Non-trainable params\n","110 M     Total params\n","442.509   Total estimated model params size (MB)\n"]},{"output_type":"display_data","data":{"text/plain":["Sanity Checking: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b2afd5fa9014ecea5cc84070cc8c8ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Training: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be939b07a14a420281ae64cd9c4ac597"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57dafe9a5a1c43e98cf9d1dd0b28e05c"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.callbacks.early_stopping:Metric val_f1score improved. New best score: 0.756\n","INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 414: 'val_f1score' reached 0.75605 (best 0.75605), saving model to '/content/drive/MyDrive/Colab Notebooks/DACON/문장_유형_분류_AI_경진대회/fold2/epoch=0-step=414-train_f1score=0.47058823704719543-val_f1score=0.76.ckpt' as top 5\n"]},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0235e6a02fb647abb4519ce3d67017e0"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.callbacks.early_stopping:Metric val_f1score improved by 0.006 >= min_delta = 0.0. New best score: 0.762\n","INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 828: 'val_f1score' reached 0.76179 (best 0.76179), saving model to '/content/drive/MyDrive/Colab Notebooks/DACON/문장_유형_분류_AI_경진대회/fold2/epoch=1-step=828-train_f1score=0.7058823704719543-val_f1score=0.76.ckpt' as top 5\n"]},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34dfa9fdb8ab404b9989e766b89f8eb3"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.callbacks.early_stopping:Metric val_f1score improved by 0.003 >= min_delta = 0.0. New best score: 0.765\n","INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 1242: 'val_f1score' reached 0.76481 (best 0.76481), saving model to '/content/drive/MyDrive/Colab Notebooks/DACON/문장_유형_분류_AI_경진대회/fold2/epoch=2-step=1242-train_f1score=0.8235294222831726-val_f1score=0.76.ckpt' as top 5\n"]},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b839d07a5c3d4ecd90989bbfead9260d"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.callbacks.early_stopping:Metric val_f1score improved by 0.002 >= min_delta = 0.0. New best score: 0.767\n","INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 1656: 'val_f1score' reached 0.76663 (best 0.76663), saving model to '/content/drive/MyDrive/Colab Notebooks/DACON/문장_유형_분류_AI_경진대회/fold2/epoch=3-step=1656-train_f1score=0.7058823704719543-val_f1score=0.77.ckpt' as top 5\n"]},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12093ea681bd48e89ba10168d3e9d715"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 4, global step 2070: 'val_f1score' reached 0.75484 (best 0.76663), saving model to '/content/drive/MyDrive/Colab Notebooks/DACON/문장_유형_분류_AI_경진대회/fold2/epoch=4-step=2070-train_f1score=1.0-val_f1score=0.75.ckpt' as top 5\n"]},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b36783aba454422191cb5d7e447e54cb"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 5, global step 2484: 'val_f1score' reached 0.76179 (best 0.76663), saving model to '/content/drive/MyDrive/Colab Notebooks/DACON/문장_유형_분류_AI_경진대회/fold2/epoch=5-step=2484-train_f1score=0.8823529481887817-val_f1score=0.76.ckpt' as top 5\n"]},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edf19d410118400ea9ae52851d3a6f66"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 6, global step 2898: 'val_f1score' was not in top 5\n"]},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecba436dafc44017bb73a0d6dfe97119"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 7, global step 3312: 'val_f1score' was not in top 5\n"]},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"415606cc48be4922b735da9e99199420"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 8, global step 3726: 'val_f1score' was not in top 5\n","INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=9` reached.\n"]},{"output_type":"stream","name":"stdout","text":["3\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name                     | Type         | Params\n","----------------------------------------------------------\n","0 | model                    | RobertaModel | 110 M \n","1 | type_classification      | Linear       | 3.1 K \n","2 | polarity_classification  | Linear       | 2.3 K \n","3 | tense_classification     | Linear       | 2.3 K \n","4 | certainty_classification | Linear       | 1.5 K \n","----------------------------------------------------------\n","110 M     Trainable params\n","0         Non-trainable params\n","110 M     Total params\n","442.509   Total estimated model params size (MB)\n"]},{"output_type":"display_data","data":{"text/plain":["Sanity Checking: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fa4aae254da4884b1a1f01ae6ff92e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Training: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81dec08dc28d424db1f7032372ce6916"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63440ef5cf6f4b82abdc5afe3f4c1b2a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.callbacks.early_stopping:Metric val_f1score improved. New best score: 0.751\n","INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 414: 'val_f1score' reached 0.75121 (best 0.75121), saving model to '/content/drive/MyDrive/Colab Notebooks/DACON/문장_유형_분류_AI_경진대회/fold3/epoch=0-step=414-train_f1score=0.7647058963775635-val_f1score=0.75.ckpt' as top 5\n"]},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00fbe7d0d7f849b49c3950e80c26d6c2"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.callbacks.early_stopping:Metric val_f1score improved by 0.010 >= min_delta = 0.0. New best score: 0.761\n","INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 828: 'val_f1score' reached 0.76088 (best 0.76088), saving model to '/content/drive/MyDrive/Colab Notebooks/DACON/문장_유형_분류_AI_경진대회/fold3/epoch=1-step=828-train_f1score=0.8235294222831726-val_f1score=0.76.ckpt' as top 5\n"]},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44cac819299a4ce1921ac884201fc328"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 1242: 'val_f1score' reached 0.75907 (best 0.76088), saving model to '/content/drive/MyDrive/Colab Notebooks/DACON/문장_유형_분류_AI_경진대회/fold3/epoch=2-step=1242-train_f1score=0.7647058963775635-val_f1score=0.76.ckpt' as top 5\n"]},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9abebb79a08848eb849a2585abb620a5"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 1656: 'val_f1score' reached 0.75272 (best 0.76088), saving model to '/content/drive/MyDrive/Colab Notebooks/DACON/문장_유형_분류_AI_경진대회/fold3/epoch=3-step=1656-train_f1score=0.7058823704719543-val_f1score=0.75.ckpt' as top 5\n"]},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61bb9caed5fa4de0b73f8953b178e8f6"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 4, global step 2070: 'val_f1score' reached 0.75212 (best 0.76088), saving model to '/content/drive/MyDrive/Colab Notebooks/DACON/문장_유형_분류_AI_경진대회/fold3/epoch=4-step=2070-train_f1score=0.8823529481887817-val_f1score=0.75.ckpt' as top 5\n"]},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4a2efd426e7484183ca7eb020adc881"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 5, global step 2484: 'val_f1score' was not in top 5\n"]},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"849b2c167f71417bbd6d1d5a59b13a8f"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 6, global step 2898: 'val_f1score' was not in top 5\n"]},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f54e21c97d414d828bac5d52fa155fa1"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.callbacks.early_stopping:Monitored metric val_f1score did not improve in the last 6 records. Best score: 0.761. Signaling Trainer to stop.\n","INFO:pytorch_lightning.utilities.rank_zero:Epoch 7, global step 3312: 'val_f1score' was not in top 5\n"]},{"output_type":"stream","name":"stdout","text":["4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name                     | Type         | Params\n","----------------------------------------------------------\n","0 | model                    | RobertaModel | 110 M \n","1 | type_classification      | Linear       | 3.1 K \n","2 | polarity_classification  | Linear       | 2.3 K \n","3 | tense_classification     | Linear       | 2.3 K \n","4 | certainty_classification | Linear       | 1.5 K \n","----------------------------------------------------------\n","110 M     Trainable params\n","0         Non-trainable params\n","110 M     Total params\n","442.509   Total estimated model params size (MB)\n"]},{"output_type":"display_data","data":{"text/plain":["Sanity Checking: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2206d125f63472abc248611b6f5921d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Training: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8be18051d844017b2a324e1ce20655e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1532d399db0a4bba871314a2289b3178"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.callbacks.early_stopping:Metric val_f1score improved. New best score: 0.750\n","INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 414: 'val_f1score' reached 0.75030 (best 0.75030), saving model to '/content/drive/MyDrive/Colab Notebooks/DACON/문장_유형_분류_AI_경진대회/fold4/epoch=0-step=414-train_f1score=0.7058823704719543-val_f1score=0.75.ckpt' as top 5\n"]},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f18d438f0f4488d8c47f6008555eb4f"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 828: 'val_f1score' reached 0.74516 (best 0.75030), saving model to '/content/drive/MyDrive/Colab Notebooks/DACON/문장_유형_분류_AI_경진대회/fold4/epoch=1-step=828-train_f1score=0.8235294222831726-val_f1score=0.75.ckpt' as top 5\n"]},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"002f897806ed4bb3bc63218b2fc8d9f1"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 1242: 'val_f1score' reached 0.74577 (best 0.75030), saving model to '/content/drive/MyDrive/Colab Notebooks/DACON/문장_유형_분류_AI_경진대회/fold4/epoch=2-step=1242-train_f1score=0.8235294222831726-val_f1score=0.75.ckpt' as top 5\n"]},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4812f150f1954a00b574a0b2fc2f7250"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.callbacks.early_stopping:Metric val_f1score improved by 0.002 >= min_delta = 0.0. New best score: 0.752\n","INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 1656: 'val_f1score' reached 0.75242 (best 0.75242), saving model to '/content/drive/MyDrive/Colab Notebooks/DACON/문장_유형_분류_AI_경진대회/fold4/epoch=3-step=1656-train_f1score=0.8823529481887817-val_f1score=0.75.ckpt' as top 5\n"]},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"606f79e8ce1f474c8a33f43d2ba57421"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 4, global step 2070: 'val_f1score' reached 0.74667 (best 0.75242), saving model to '/content/drive/MyDrive/Colab Notebooks/DACON/문장_유형_분류_AI_경진대회/fold4/epoch=4-step=2070-train_f1score=0.8823529481887817-val_f1score=0.75.ckpt' as top 5\n"]},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d64ea394ffd4422ba24da1d6b897f838"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 5, global step 2484: 'val_f1score' reached 0.74788 (best 0.75242), saving model to '/content/drive/MyDrive/Colab Notebooks/DACON/문장_유형_분류_AI_경진대회/fold4/epoch=5-step=2484-train_f1score=0.8823529481887817-val_f1score=0.75.ckpt' as top 5\n"]},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb3e2f3915fd4d6f9d7151ced03e4cad"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 6, global step 2898: 'val_f1score' was not in top 5\n"]},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d4befc6a6c84b2c919ef6eacf946144"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 7, global step 3312: 'val_f1score' was not in top 5\n"]},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d42523c0e9b4466b9b5b52b126b6ccb9"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 8, global step 3726: 'val_f1score' was not in top 5\n","INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=9` reached.\n"]}],"source":["from pytorch_lightning.callbacks import RichProgressBar, EarlyStopping, ModelCheckpoint\n","\n","\n","skf = StratifiedKFold(n_splits = 5, random_state=428, shuffle=True)\n","\n","model_name = \"klue/roberta-base\"\n","\n","for idx, (train_index, valid_index) in enumerate(skf.split(dataset, train_df['label_라벨인코딩'])):\n","    print(idx)\n","    if idx == 0:\n","        continue\n","    dirpath = f\"/content/drive/MyDrive/Colab Notebooks/DACON/문장_유형_분류_AI_경진대회/fold{idx}\"\n","    checkpoint_callback = ModelCheckpoint(\n","    dirpath=dirpath,\n","    save_top_k =5,\n","    filename='{epoch}-{step}-{train_f1score}-{val_f1score:.2f}',\n","    verbose=True,\n","    monitor='val_f1score',\n","    mode='max'\n","    )\n","    \n","    train_dataset = select_split(dataset, train_index)\n","    valid_dataset = select_split(dataset, valid_index)\n","    train_dataloader = DataLoader(train_dataset, batch_size = 32, collate_fn=TextClassificationCollator(model_name=model_name), shuffle = True)\n","    valid_dataloader = DataLoader(valid_dataset, batch_size = 32, collate_fn=TextClassificationCollator(model_name=model_name), shuffle = False)\n","    \n","    bert = ClassifySentenceType(model_name=model_name)\n","    trainer = pl.Trainer(max_epochs = 9, accelerator=\"gpu\", accumulate_grad_batches = 1, \n","                         callbacks=[EarlyStopping('val_f1score', patience = 6, mode='max', verbose = True), checkpoint_callback])\n","    trainer.fit(bert, train_dataloader, valid_dataloader)\n","    del trainer, bert, train_dataset, valid_dataset, train_dataloader, valid_dataloader\n","    torch.cuda.empty_cache() "]},{"cell_type":"markdown","source":["## 테스트 데이터에 대한 예측 수행"],"metadata":{"id":"15hyU2H5LOa8"}},{"cell_type":"code","source":["model_name = \"klue/roberta-base\"\n","test_dataloader = DataLoader(test_dataset, batch_size = 40, collate_fn=TextClassificationCollator(model_name=model_name, train = True), shuffle = False)"],"metadata":{"id":"JaRnDoedLjFR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["models = [\n","    \"/content/drive/MyDrive/Colab Notebooks/DACON/문장_유형_분류_AI_경진대회/fold0/epoch=11-step=3972-train_f1score=1.0-val_f1score=0.99.ckpt\",\n","    \"/content/drive/MyDrive/Colab Notebooks/DACON/문장_유형_분류_AI_경진대회/fold1/epoch=2-step=1242-train_f1score=1.0-val_f1score=0.76.ckpt\",\n","    \"/content/drive/MyDrive/Colab Notebooks/DACON/문장_유형_분류_AI_경진대회/fold2/epoch=5-step=2484-train_f1score=0.8823529481887817-val_f1score=0.76.ckpt\",\n","    \"/content/drive/MyDrive/Colab Notebooks/DACON/문장_유형_분류_AI_경진대회/fold3/epoch=4-step=2070-train_f1score=0.8823529481887817-val_f1score=0.75.ckpt\",\n","    \"/content/drive/MyDrive/Colab Notebooks/DACON/문장_유형_분류_AI_경진대회/fold4/epoch=5-step=2484-train_f1score=0.8823529481887817-val_f1score=0.75.ckpt\"\n","]\n","\n","preds = []\n","for i in range(5):\n","    temp = torch.load(models[i])\n","    m = ClassifySentenceType(model_name = \"klue/roberta-base\")\n","    m.load_state_dict(temp['state_dict'])\n","    trainer = pl.Trainer(accelerator=\"gpu\")\n","    preds.append(trainer.predict(m, test_dataloader))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["72d89339346e45caaf4c08152636501c","b026afa66cb141228dc7646b4ef6f671","a07a23a175934d4eb8d0abad36eb3791","f7193b4178694483a29b6d22604f86cd","d2ec1d1c80214e869491d056843897e2","b00a62058ce943079db66cf856c7ff21","28b11a81522d4686889548d63e4b4429","15ec6b0587d54322af1762c3cbcd3135","7ee1ac20d61d4062a0e385b609aab862","654d37bdeb254052803c19848b58847c","4047c14d608a40ec9338b08ba1428ebd","7d74cde1224c47b9babcbfc0e0e28562","73e7b46daebc4ca0a429b8ee38ef4798","0f55b2102d0a45d28d8ad9313b302d8b","99c3cc75b8b24cf280471eece8e524b1","5d1fb817bc324335b0d21654dc302da0","bfd977ce5b2c4e368a4eb88c085a8461","f6451ade4caa4f0f978b2a594a284d35","edd2506ab6964ebdace6d72ade44c6d1","7a538026aec34e18a3bb1669948adb32","e95c5067fc3c4ae4a5258776f6555034","15da56fa92b04c3180e916f18885066b","82c890dda57749e6bc530fa2e2f9efa2","b7ffd09eb7c5458db5c9cb033d84b477","82f80140275f4156a7cf771855fdc859","bcb51087ce544547b4cc770f2497332e","da26cda43f0b4d07b6ce32544d9e5a98","6ad6102d913044b2b9393b224ce7345a","345d063466db45d7a7a1be0f74250e92","00ca6edc645c46548ea7530e328205c8","496e5e8c687444df8bad8c3775c373b7","e8ad4cbb3dd74235a0bfe77faa8a89e1","e68bb5367a5c4862abab41a950ea5640","6e09f0f74a0c4ff2ad70ce6fca646729","d0607c96cd8a4cdb86bfc5a1e6b79703","668698c9052f4a2ca2aa883064a64d6d","d6dd5f91b0cd404faac6040cb8fcd7eb","024a985fdf3247cca4f826f99471fa55","3d048494adc44cd0861d7fea953ad17b","cecb1732ae7b41868e583f9c820c9672","edf1e4afb81d4391a885256a9eb0d50d","4eb3e57784d148348ce0efc2eaff582f","78bdf44fed9c4870aadee4cdc642f808","9399bd7e83c241d0918c06ac50eca3c0","589afd0a3f9d416b82d620d7891dd7fa","d4aea1ad439b449496a54b303d9db2a9","17dbc8fbdfeb47b0ac7d438a89cfba5d","9120d7b64e5e4da89383556087b7242b","66dcb168f00642cb822e2984cd5e76c3","b704c827d96a43e6a92868a68c72186f","4069386d33554de8b3f4e23c4ab280d0","294f287901a1401e8572797e039712dc","ffef7cf254ea4ea5b3471ed2518b8231","be27d742466d4694a4d1fe1790e52fb0","627b01d7b2ce4821a0a585d6328bdff1"]},"id":"DAfORkUxIIya","executionInfo":{"status":"ok","timestamp":1671753816454,"user_tz":-540,"elapsed":239481,"user":{"displayName":"jaewook Lee","userId":"02714897352724258647"}},"outputId":"5abedb05-436f-4dbe-9015-806f7bde7c92"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: /content/lightning_logs\n","INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"display_data","data":{"text/plain":["Predicting: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72d89339346e45caaf4c08152636501c"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: /content/lightning_logs\n","INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"display_data","data":{"text/plain":["Predicting: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d74cde1224c47b9babcbfc0e0e28562"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: /content/lightning_logs\n","INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"display_data","data":{"text/plain":["Predicting: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82c890dda57749e6bc530fa2e2f9efa2"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: /content/lightning_logs\n","INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"display_data","data":{"text/plain":["Predicting: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e09f0f74a0c4ff2ad70ce6fca646729"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: /content/lightning_logs\n","INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"display_data","data":{"text/plain":["Predicting: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"589afd0a3f9d416b82d620d7891dd7fa"}},"metadata":{}}]},{"cell_type":"code","source":["num = 0\n","one_type_hat = preds[num][0]['type']\n","one_polarity_hat = preds[num][0]['polarity']\n","one_tense_hat = preds[num][0]['tense']\n","one_certainty_hat = preds[num][0]['certainty']\n","\n","for i in range(len(preds[num])):\n","    if i == 0:\n","        continue\n","    else:\n","        one_type_hat = torch.vstack((one_type_hat, preds[num][i]['type']))\n","        one_polarity_hat = torch.vstack((one_polarity_hat, preds[num][i]['polarity']))\n","        one_tense_hat = torch.vstack((one_tense_hat, preds[num][i]['tense']))\n","        one_certainty_hat = torch.vstack((one_certainty_hat, preds[num][i]['certainty']))\n","\n","num = 1\n","two_type_hat = preds[num][0]['type']\n","two_polarity_hat = preds[num][0]['polarity']\n","two_tense_hat = preds[num][0]['tense']\n","two_certainty_hat = preds[num][0]['certainty']\n","\n","for i in range(len(preds[num])):\n","    if i == 0:\n","        continue\n","    else:\n","        two_type_hat = torch.vstack((two_type_hat, preds[num][i]['type']))\n","        two_polarity_hat = torch.vstack((two_polarity_hat, preds[num][i]['polarity']))\n","        two_tense_hat = torch.vstack((two_tense_hat, preds[num][i]['tense']))\n","        two_certainty_hat = torch.vstack((two_certainty_hat, preds[num][i]['certainty']))\n","\n","num = 2\n","three_type_hat = preds[num][0]['type']\n","three_polarity_hat = preds[num][0]['polarity']\n","three_tense_hat = preds[num][0]['tense']\n","three_certainty_hat = preds[num][0]['certainty']\n","\n","for i in range(len(preds[num])):\n","    if i == 0:\n","        continue\n","    else:\n","        three_type_hat = torch.vstack((three_type_hat, preds[num][i]['type']))\n","        three_polarity_hat = torch.vstack((three_polarity_hat, preds[num][i]['polarity']))\n","        three_tense_hat = torch.vstack((three_tense_hat, preds[num][i]['tense']))\n","        three_certainty_hat = torch.vstack((three_certainty_hat, preds[num][i]['certainty']))\n","\n","num = 3\n","four_type_hat = preds[num][0]['type']\n","four_polarity_hat = preds[num][0]['polarity']\n","four_tense_hat = preds[num][0]['tense']\n","four_certainty_hat = preds[num][0]['certainty']\n","\n","for i in range(len(preds[num])):\n","    if i == 0:\n","        continue\n","    else:\n","        four_type_hat = torch.vstack((four_type_hat, preds[num][i]['type']))\n","        four_polarity_hat = torch.vstack((four_polarity_hat, preds[num][i]['polarity']))\n","        four_tense_hat = torch.vstack((four_tense_hat, preds[num][i]['tense']))\n","        four_certainty_hat = torch.vstack((four_certainty_hat, preds[num][i]['certainty']))\n","\n","num = 4\n","five_type_hat = preds[num][0]['type']\n","five_polarity_hat = preds[num][0]['polarity']\n","five_tense_hat = preds[num][0]['tense']\n","five_certainty_hat = preds[num][0]['certainty']\n","\n","for i in range(len(preds[num])):\n","    if i == 0:\n","        continue\n","    else:\n","        five_type_hat = torch.vstack((five_type_hat, preds[num][i]['type']))\n","        five_polarity_hat = torch.vstack((five_polarity_hat, preds[num][i]['polarity']))\n","        five_tense_hat = torch.vstack((five_tense_hat, preds[num][i]['tense']))\n","        five_certainty_hat = torch.vstack((five_certainty_hat, preds[num][i]['certainty']))"],"metadata":{"id":"YLl9PborNbj0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["final_type_hat = (one_type_hat + two_type_hat + three_type_hat + four_type_hat + five_type_hat)\n","final_polarity_hat = (one_polarity_hat + two_polarity_hat + three_polarity_hat + four_polarity_hat + five_polarity_hat)\n","final_tense_hat = (one_tense_hat + two_tense_hat + three_tense_hat + four_tense_hat + five_tense_hat)\n","final_certainty_hat = (one_certainty_hat + two_certainty_hat + three_certainty_hat + four_certainty_hat+five_certainty_hat)"],"metadata":{"id":"V1BzvdyMPdiW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(final_type_hat.shape)\n","print(final_polarity_hat.shape)\n","print(final_tense_hat.shape)\n","print(final_certainty_hat.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sHG-SM5SPaeW","executionInfo":{"status":"ok","timestamp":1671753088496,"user_tz":-540,"elapsed":2,"user":{"displayName":"jaewook Lee","userId":"02714897352724258647"}},"outputId":"37f25244-626a-4827-ae19-9a0e84b99eb3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([7090, 4])\n","torch.Size([7090, 3])\n","torch.Size([7090, 3])\n","torch.Size([7090, 2])\n"]}]},{"cell_type":"code","source":["type_ = type_le.inverse_transform(final_type_hat.argmax(dim = -1).tolist())\n","polarity_ = polarity_le.inverse_transform(final_polarity_hat.argmax(dim = -1).tolist())\n","tense_ = tense_le.inverse_transform(final_tense_hat.argmax(dim = -1).tolist())\n","certainty_ = certainty_le.inverse_transform(final_certainty_hat.argmax(dim = -1).tolist())"],"metadata":{"id":"ZXBdLXh4O5C4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels = []\n","for idx in range(type_.shape[0]):\n","    temp = f\"{type_[idx]}-{polarity_[idx]}-{tense_[idx]}-{certainty_[idx]}\"\n","    labels.append(temp)"],"metadata":{"id":"30idhvn5QJZM"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6SO2AZqM_0rJ"},"outputs":[],"source":["submit = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/DACON/문장_유형_분류_AI_경진대회/sample_submission.csv\")\n","submit['label'] = labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2xljkAXpzuZh","executionInfo":{"status":"ok","timestamp":1671753269532,"user_tz":-540,"elapsed":284,"user":{"displayName":"jaewook Lee","userId":"02714897352724258647"}},"colab":{"base_uri":"https://localhost:8080/","height":206},"outputId":"3ff2a495-6d45-48e9-9603-9d90de98a6e5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["          ID         label\n","0  TEST_0000  사실형-긍정-현재-확실\n","1  TEST_0001  사실형-긍정-현재-확실\n","2  TEST_0002  사실형-긍정-과거-확실\n","3  TEST_0003  사실형-긍정-과거-확실\n","4  TEST_0004  사실형-긍정-과거-확실"],"text/html":["\n","  <div id=\"df-1d41e0a3-dfce-4cd4-b826-2731da7410f5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>TEST_0000</td>\n","      <td>사실형-긍정-현재-확실</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>TEST_0001</td>\n","      <td>사실형-긍정-현재-확실</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>TEST_0002</td>\n","      <td>사실형-긍정-과거-확실</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>TEST_0003</td>\n","      <td>사실형-긍정-과거-확실</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>TEST_0004</td>\n","      <td>사실형-긍정-과거-확실</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d41e0a3-dfce-4cd4-b826-2731da7410f5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1d41e0a3-dfce-4cd4-b826-2731da7410f5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1d41e0a3-dfce-4cd4-b826-2731da7410f5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":81}],"source":["submit.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZVhRrnfPzuc5"},"outputs":[],"source":["submit.to_csv('/content/drive/MyDrive/Colab Notebooks/DACON/문장_유형_분류_AI_경진대회/baseline_submit.csv', index=False)"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"1ECLQkYBxK6zZxdGPTK1jD7evUQCB4eqK","timestamp":1671764319762},{"file_id":"1gfwfFkjMe8Bp01aP9Osu6n5UG1TIjv80","timestamp":1671750802669}],"authorship_tag":"ABX9TyP7luelwAMv1Qh5+EFmPRrA"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"72d89339346e45caaf4c08152636501c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b026afa66cb141228dc7646b4ef6f671","IPY_MODEL_a07a23a175934d4eb8d0abad36eb3791","IPY_MODEL_f7193b4178694483a29b6d22604f86cd"],"layout":"IPY_MODEL_d2ec1d1c80214e869491d056843897e2"}},"b026afa66cb141228dc7646b4ef6f671":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b00a62058ce943079db66cf856c7ff21","placeholder":"​","style":"IPY_MODEL_28b11a81522d4686889548d63e4b4429","value":"Predicting DataLoader 0: 100%"}},"a07a23a175934d4eb8d0abad36eb3791":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_15ec6b0587d54322af1762c3cbcd3135","max":178,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7ee1ac20d61d4062a0e385b609aab862","value":178}},"f7193b4178694483a29b6d22604f86cd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_654d37bdeb254052803c19848b58847c","placeholder":"​","style":"IPY_MODEL_4047c14d608a40ec9338b08ba1428ebd","value":" 178/178 [00:36&lt;00:00,  4.82it/s]"}},"d2ec1d1c80214e869491d056843897e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"b00a62058ce943079db66cf856c7ff21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28b11a81522d4686889548d63e4b4429":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"15ec6b0587d54322af1762c3cbcd3135":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ee1ac20d61d4062a0e385b609aab862":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"654d37bdeb254052803c19848b58847c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4047c14d608a40ec9338b08ba1428ebd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7d74cde1224c47b9babcbfc0e0e28562":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_73e7b46daebc4ca0a429b8ee38ef4798","IPY_MODEL_0f55b2102d0a45d28d8ad9313b302d8b","IPY_MODEL_99c3cc75b8b24cf280471eece8e524b1"],"layout":"IPY_MODEL_5d1fb817bc324335b0d21654dc302da0"}},"73e7b46daebc4ca0a429b8ee38ef4798":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bfd977ce5b2c4e368a4eb88c085a8461","placeholder":"​","style":"IPY_MODEL_f6451ade4caa4f0f978b2a594a284d35","value":"Predicting DataLoader 0: 100%"}},"0f55b2102d0a45d28d8ad9313b302d8b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_edd2506ab6964ebdace6d72ade44c6d1","max":178,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7a538026aec34e18a3bb1669948adb32","value":178}},"99c3cc75b8b24cf280471eece8e524b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e95c5067fc3c4ae4a5258776f6555034","placeholder":"​","style":"IPY_MODEL_15da56fa92b04c3180e916f18885066b","value":" 178/178 [00:35&lt;00:00,  5.00it/s]"}},"5d1fb817bc324335b0d21654dc302da0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"bfd977ce5b2c4e368a4eb88c085a8461":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6451ade4caa4f0f978b2a594a284d35":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"edd2506ab6964ebdace6d72ade44c6d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a538026aec34e18a3bb1669948adb32":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e95c5067fc3c4ae4a5258776f6555034":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15da56fa92b04c3180e916f18885066b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82c890dda57749e6bc530fa2e2f9efa2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b7ffd09eb7c5458db5c9cb033d84b477","IPY_MODEL_82f80140275f4156a7cf771855fdc859","IPY_MODEL_bcb51087ce544547b4cc770f2497332e"],"layout":"IPY_MODEL_da26cda43f0b4d07b6ce32544d9e5a98"}},"b7ffd09eb7c5458db5c9cb033d84b477":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ad6102d913044b2b9393b224ce7345a","placeholder":"​","style":"IPY_MODEL_345d063466db45d7a7a1be0f74250e92","value":"Predicting DataLoader 0: 100%"}},"82f80140275f4156a7cf771855fdc859":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_00ca6edc645c46548ea7530e328205c8","max":178,"min":0,"orientation":"horizontal","style":"IPY_MODEL_496e5e8c687444df8bad8c3775c373b7","value":178}},"bcb51087ce544547b4cc770f2497332e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8ad4cbb3dd74235a0bfe77faa8a89e1","placeholder":"​","style":"IPY_MODEL_e68bb5367a5c4862abab41a950ea5640","value":" 178/178 [00:35&lt;00:00,  4.95it/s]"}},"da26cda43f0b4d07b6ce32544d9e5a98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"6ad6102d913044b2b9393b224ce7345a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"345d063466db45d7a7a1be0f74250e92":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"00ca6edc645c46548ea7530e328205c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"496e5e8c687444df8bad8c3775c373b7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e8ad4cbb3dd74235a0bfe77faa8a89e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e68bb5367a5c4862abab41a950ea5640":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6e09f0f74a0c4ff2ad70ce6fca646729":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d0607c96cd8a4cdb86bfc5a1e6b79703","IPY_MODEL_668698c9052f4a2ca2aa883064a64d6d","IPY_MODEL_d6dd5f91b0cd404faac6040cb8fcd7eb"],"layout":"IPY_MODEL_024a985fdf3247cca4f826f99471fa55"}},"d0607c96cd8a4cdb86bfc5a1e6b79703":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d048494adc44cd0861d7fea953ad17b","placeholder":"​","style":"IPY_MODEL_cecb1732ae7b41868e583f9c820c9672","value":"Predicting DataLoader 0: 100%"}},"668698c9052f4a2ca2aa883064a64d6d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_edf1e4afb81d4391a885256a9eb0d50d","max":178,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4eb3e57784d148348ce0efc2eaff582f","value":178}},"d6dd5f91b0cd404faac6040cb8fcd7eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_78bdf44fed9c4870aadee4cdc642f808","placeholder":"​","style":"IPY_MODEL_9399bd7e83c241d0918c06ac50eca3c0","value":" 178/178 [00:35&lt;00:00,  4.95it/s]"}},"024a985fdf3247cca4f826f99471fa55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"3d048494adc44cd0861d7fea953ad17b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cecb1732ae7b41868e583f9c820c9672":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"edf1e4afb81d4391a885256a9eb0d50d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4eb3e57784d148348ce0efc2eaff582f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"78bdf44fed9c4870aadee4cdc642f808":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9399bd7e83c241d0918c06ac50eca3c0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"589afd0a3f9d416b82d620d7891dd7fa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d4aea1ad439b449496a54b303d9db2a9","IPY_MODEL_17dbc8fbdfeb47b0ac7d438a89cfba5d","IPY_MODEL_9120d7b64e5e4da89383556087b7242b"],"layout":"IPY_MODEL_66dcb168f00642cb822e2984cd5e76c3"}},"d4aea1ad439b449496a54b303d9db2a9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b704c827d96a43e6a92868a68c72186f","placeholder":"​","style":"IPY_MODEL_4069386d33554de8b3f4e23c4ab280d0","value":"Predicting DataLoader 0: 100%"}},"17dbc8fbdfeb47b0ac7d438a89cfba5d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_294f287901a1401e8572797e039712dc","max":178,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ffef7cf254ea4ea5b3471ed2518b8231","value":178}},"9120d7b64e5e4da89383556087b7242b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be27d742466d4694a4d1fe1790e52fb0","placeholder":"​","style":"IPY_MODEL_627b01d7b2ce4821a0a585d6328bdff1","value":" 178/178 [00:35&lt;00:00,  4.96it/s]"}},"66dcb168f00642cb822e2984cd5e76c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"b704c827d96a43e6a92868a68c72186f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4069386d33554de8b3f4e23c4ab280d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"294f287901a1401e8572797e039712dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ffef7cf254ea4ea5b3471ed2518b8231":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"be27d742466d4694a4d1fe1790e52fb0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"627b01d7b2ce4821a0a585d6328bdff1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}